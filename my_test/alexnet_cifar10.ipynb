{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "TASK_NAME = \"alexnet_cifar10\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "from src.models.AlexNet_CIFAR10 import AlexNet_CIFAR10\n",
    "from src.models.AlexNet_CIFAR10LowRank import getBase, AlexNet_CIFAR10LowRank, load_sd_decomp\n",
    "\n",
    "import src.main as lc\n",
    "from src.utils.utils import evaluate_accuracy, lazy_restore, evaluate_compression\n",
    "import old_lc.main as olc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import json\n",
    "\n",
    "# 加载 MNIST 数据集\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data_CIFAR10', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data_CIFAR10', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 选择设备（GPU or CPU）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "PRE_TRAINED = \"./my_test/\" + TASK_NAME + \"/pretrained_model.pth\"\n",
    "if not os.path.exists(\"./my_test/\" + TASK_NAME):\n",
    "    os.makedirs(\"./my_test/\" + TASK_NAME)\n",
    "\n",
    "def accuracy_cal(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Accuracy 10.00%, Loss: 0.0015\n",
      "Epoch 1, Accuracy 10.01%, Loss: 0.1488\n",
      "Epoch 1, Accuracy 10.03%, Loss: 0.2961\n",
      "Epoch 1, Accuracy 10.00%, Loss: 0.4434\n",
      "Epoch 1, Accuracy 10.00%, Loss: 0.5907\n",
      "Epoch 1, Accuracy 10.00%, Loss: 0.7381\n",
      "Epoch 1, Accuracy 10.00%, Loss: 0.8854\n",
      "Epoch 1, Accuracy 10.00%, Loss: 1.0327\n",
      "Epoch 1, Accuracy 10.00%, Loss: 1.1800\n",
      "Epoch 1, Accuracy 9.77%, Loss: 1.3273\n",
      "Epoch 1, Accuracy 10.00%, Loss: 1.4747\n",
      "Epoch 1, Accuracy 13.41%, Loss: 1.6220\n",
      "Epoch 1, Accuracy 10.08%, Loss: 1.7693\n",
      "Epoch 1, Accuracy 12.93%, Loss: 1.9166\n",
      "Epoch 1, Accuracy 10.00%, Loss: 2.0639\n",
      "Epoch 1, Accuracy 13.50%, Loss: 2.2112\n",
      "Epoch 2, Accuracy 14.70%, Loss: 0.0015\n",
      "Epoch 2, Accuracy 10.00%, Loss: 0.1488\n",
      "Epoch 2, Accuracy 10.00%, Loss: 0.2960\n",
      "Epoch 2, Accuracy 10.00%, Loss: 0.4433\n",
      "Epoch 2, Accuracy 10.00%, Loss: 0.5906\n",
      "Epoch 2, Accuracy 10.00%, Loss: 0.7379\n",
      "Epoch 2, Accuracy 12.90%, Loss: 0.8852\n",
      "Epoch 2, Accuracy 12.77%, Loss: 1.0325\n",
      "Epoch 2, Accuracy 10.00%, Loss: 1.1797\n",
      "Epoch 2, Accuracy 12.20%, Loss: 1.3270\n",
      "Epoch 2, Accuracy 14.88%, Loss: 1.4742\n",
      "Epoch 2, Accuracy 18.47%, Loss: 1.6214\n",
      "Epoch 2, Accuracy 17.48%, Loss: 1.7685\n",
      "Epoch 2, Accuracy 21.80%, Loss: 1.9157\n",
      "Epoch 2, Accuracy 15.49%, Loss: 2.0627\n",
      "Epoch 2, Accuracy 23.47%, Loss: 2.2096\n",
      "Epoch 3, Accuracy 24.13%, Loss: 0.0015\n",
      "Epoch 3, Accuracy 23.89%, Loss: 0.1478\n",
      "Epoch 3, Accuracy 23.58%, Loss: 0.2930\n",
      "Epoch 3, Accuracy 23.86%, Loss: 0.4327\n",
      "Epoch 3, Accuracy 26.34%, Loss: 0.5672\n",
      "Epoch 3, Accuracy 25.12%, Loss: 0.7002\n",
      "Epoch 3, Accuracy 27.37%, Loss: 0.8295\n",
      "Epoch 3, Accuracy 25.84%, Loss: 0.9600\n",
      "Epoch 3, Accuracy 27.12%, Loss: 1.0880\n",
      "Epoch 3, Accuracy 27.59%, Loss: 1.2128\n",
      "Epoch 3, Accuracy 29.91%, Loss: 1.3377\n",
      "Epoch 3, Accuracy 31.21%, Loss: 1.4630\n",
      "Epoch 3, Accuracy 29.02%, Loss: 1.5856\n",
      "Epoch 3, Accuracy 32.76%, Loss: 1.7075\n",
      "Epoch 3, Accuracy 33.44%, Loss: 1.8288\n",
      "Epoch 3, Accuracy 32.47%, Loss: 1.9483\n",
      "Epoch 4, Accuracy 34.35%, Loss: 0.0012\n",
      "Epoch 4, Accuracy 31.01%, Loss: 0.1171\n",
      "Epoch 4, Accuracy 36.39%, Loss: 0.2314\n",
      "Epoch 4, Accuracy 36.87%, Loss: 0.3449\n",
      "Epoch 4, Accuracy 36.78%, Loss: 0.4579\n",
      "Epoch 4, Accuracy 38.29%, Loss: 0.5706\n",
      "Epoch 4, Accuracy 39.21%, Loss: 0.6809\n",
      "Epoch 4, Accuracy 39.14%, Loss: 0.7894\n",
      "Epoch 4, Accuracy 39.06%, Loss: 0.8970\n",
      "Epoch 4, Accuracy 40.42%, Loss: 1.0054\n",
      "Epoch 4, Accuracy 36.89%, Loss: 1.1130\n",
      "Epoch 4, Accuracy 41.99%, Loss: 1.2200\n",
      "Epoch 4, Accuracy 40.86%, Loss: 1.3232\n",
      "Epoch 4, Accuracy 41.88%, Loss: 1.4269\n",
      "Epoch 4, Accuracy 41.15%, Loss: 1.5289\n",
      "Epoch 4, Accuracy 42.70%, Loss: 1.6319\n",
      "Epoch 5, Accuracy 42.40%, Loss: 0.0011\n",
      "Epoch 5, Accuracy 43.41%, Loss: 0.1021\n",
      "Epoch 5, Accuracy 43.61%, Loss: 0.2046\n",
      "Epoch 5, Accuracy 42.67%, Loss: 0.3043\n",
      "Epoch 5, Accuracy 41.86%, Loss: 0.4041\n",
      "Epoch 5, Accuracy 44.12%, Loss: 0.5047\n",
      "Epoch 5, Accuracy 44.67%, Loss: 0.6033\n",
      "Epoch 5, Accuracy 45.18%, Loss: 0.7004\n",
      "Epoch 5, Accuracy 45.48%, Loss: 0.7992\n",
      "Epoch 5, Accuracy 45.14%, Loss: 0.8966\n",
      "Epoch 5, Accuracy 45.84%, Loss: 0.9935\n",
      "Epoch 5, Accuracy 46.36%, Loss: 1.0903\n",
      "Epoch 5, Accuracy 46.22%, Loss: 1.1858\n",
      "Epoch 5, Accuracy 46.12%, Loss: 1.2807\n",
      "Epoch 5, Accuracy 46.64%, Loss: 1.3769\n",
      "Epoch 5, Accuracy 46.89%, Loss: 1.4722\n",
      "Epoch 6, Accuracy 47.16%, Loss: 0.0009\n",
      "Epoch 6, Accuracy 48.19%, Loss: 0.0930\n",
      "Epoch 6, Accuracy 47.66%, Loss: 0.1853\n",
      "Epoch 6, Accuracy 46.65%, Loss: 0.2787\n",
      "Epoch 6, Accuracy 47.38%, Loss: 0.3704\n",
      "Epoch 6, Accuracy 46.13%, Loss: 0.4625\n",
      "Epoch 6, Accuracy 49.60%, Loss: 0.5552\n",
      "Epoch 6, Accuracy 49.09%, Loss: 0.6473\n",
      "Epoch 6, Accuracy 50.09%, Loss: 0.7384\n",
      "Epoch 6, Accuracy 50.11%, Loss: 0.8280\n",
      "Epoch 6, Accuracy 49.40%, Loss: 0.9174\n",
      "Epoch 6, Accuracy 51.26%, Loss: 1.0068\n",
      "Epoch 6, Accuracy 49.55%, Loss: 1.0962\n",
      "Epoch 6, Accuracy 50.65%, Loss: 1.1835\n",
      "Epoch 6, Accuracy 51.34%, Loss: 1.2747\n",
      "Epoch 6, Accuracy 52.22%, Loss: 1.3632\n",
      "Epoch 7, Accuracy 51.53%, Loss: 0.0011\n",
      "Epoch 7, Accuracy 51.95%, Loss: 0.0856\n",
      "Epoch 7, Accuracy 53.28%, Loss: 0.1727\n",
      "Epoch 7, Accuracy 49.21%, Loss: 0.2582\n",
      "Epoch 7, Accuracy 52.29%, Loss: 0.3426\n",
      "Epoch 7, Accuracy 52.18%, Loss: 0.4274\n",
      "Epoch 7, Accuracy 53.86%, Loss: 0.5151\n",
      "Epoch 7, Accuracy 54.08%, Loss: 0.5992\n",
      "Epoch 7, Accuracy 50.64%, Loss: 0.6841\n",
      "Epoch 7, Accuracy 53.53%, Loss: 0.7681\n",
      "Epoch 7, Accuracy 53.66%, Loss: 0.8533\n",
      "Epoch 7, Accuracy 53.97%, Loss: 0.9370\n",
      "Epoch 7, Accuracy 54.11%, Loss: 1.0188\n",
      "Epoch 7, Accuracy 53.30%, Loss: 1.1022\n",
      "Epoch 7, Accuracy 55.23%, Loss: 1.1838\n",
      "Epoch 7, Accuracy 53.73%, Loss: 1.2653\n",
      "Epoch 8, Accuracy 55.68%, Loss: 0.0011\n",
      "Epoch 8, Accuracy 55.34%, Loss: 0.0812\n",
      "Epoch 8, Accuracy 54.59%, Loss: 0.1620\n",
      "Epoch 8, Accuracy 55.26%, Loss: 0.2404\n",
      "Epoch 8, Accuracy 56.60%, Loss: 0.3197\n",
      "Epoch 8, Accuracy 57.44%, Loss: 0.4021\n",
      "Epoch 8, Accuracy 57.55%, Loss: 0.4802\n",
      "Epoch 8, Accuracy 57.20%, Loss: 0.5613\n",
      "Epoch 8, Accuracy 56.79%, Loss: 0.6392\n",
      "Epoch 8, Accuracy 57.23%, Loss: 0.7143\n",
      "Epoch 8, Accuracy 58.01%, Loss: 0.7925\n",
      "Epoch 8, Accuracy 57.96%, Loss: 0.8691\n",
      "Epoch 8, Accuracy 58.74%, Loss: 0.9456\n",
      "Epoch 8, Accuracy 58.79%, Loss: 1.0223\n",
      "Epoch 8, Accuracy 57.79%, Loss: 1.1009\n",
      "Epoch 8, Accuracy 58.73%, Loss: 1.1772\n",
      "Epoch 9, Accuracy 58.58%, Loss: 0.0007\n",
      "Epoch 9, Accuracy 59.06%, Loss: 0.0777\n",
      "Epoch 9, Accuracy 56.16%, Loss: 0.1518\n",
      "Epoch 9, Accuracy 57.69%, Loss: 0.2280\n",
      "Epoch 9, Accuracy 59.52%, Loss: 0.3027\n",
      "Epoch 9, Accuracy 60.92%, Loss: 0.3755\n",
      "Epoch 9, Accuracy 58.38%, Loss: 0.4493\n",
      "Epoch 9, Accuracy 59.95%, Loss: 0.5217\n",
      "Epoch 9, Accuracy 60.57%, Loss: 0.5942\n",
      "Epoch 9, Accuracy 60.10%, Loss: 0.6675\n",
      "Epoch 9, Accuracy 61.64%, Loss: 0.7386\n",
      "Epoch 9, Accuracy 59.21%, Loss: 0.8101\n",
      "Epoch 9, Accuracy 59.06%, Loss: 0.8800\n",
      "Epoch 9, Accuracy 59.15%, Loss: 0.9519\n",
      "Epoch 9, Accuracy 62.80%, Loss: 1.0202\n",
      "Epoch 9, Accuracy 60.70%, Loss: 1.0907\n",
      "Epoch 10, Accuracy 62.22%, Loss: 0.0007\n",
      "Epoch 10, Accuracy 62.74%, Loss: 0.0717\n",
      "Epoch 10, Accuracy 61.91%, Loss: 0.1408\n",
      "Epoch 10, Accuracy 63.11%, Loss: 0.2110\n",
      "Epoch 10, Accuracy 63.72%, Loss: 0.2805\n",
      "Epoch 10, Accuracy 63.41%, Loss: 0.3495\n",
      "Epoch 10, Accuracy 62.16%, Loss: 0.4162\n",
      "Epoch 10, Accuracy 63.88%, Loss: 0.4836\n",
      "Epoch 10, Accuracy 64.05%, Loss: 0.5482\n",
      "Epoch 10, Accuracy 61.60%, Loss: 0.6151\n",
      "Epoch 10, Accuracy 60.72%, Loss: 0.6829\n",
      "Epoch 10, Accuracy 64.70%, Loss: 0.7498\n",
      "Epoch 10, Accuracy 64.27%, Loss: 0.8160\n",
      "Epoch 10, Accuracy 64.12%, Loss: 0.8841\n",
      "Epoch 10, Accuracy 63.90%, Loss: 0.9504\n",
      "Epoch 10, Accuracy 64.88%, Loss: 1.0149\n",
      "Epoch 11, Accuracy 65.00%, Loss: 0.0007\n",
      "Epoch 11, Accuracy 65.56%, Loss: 0.0656\n",
      "Epoch 11, Accuracy 65.18%, Loss: 0.1296\n",
      "Epoch 11, Accuracy 64.55%, Loss: 0.1927\n",
      "Epoch 11, Accuracy 65.91%, Loss: 0.2566\n",
      "Epoch 11, Accuracy 66.26%, Loss: 0.3200\n",
      "Epoch 11, Accuracy 66.31%, Loss: 0.3845\n",
      "Epoch 11, Accuracy 65.46%, Loss: 0.4479\n",
      "Epoch 11, Accuracy 66.23%, Loss: 0.5101\n",
      "Epoch 11, Accuracy 66.82%, Loss: 0.5719\n",
      "Epoch 11, Accuracy 67.04%, Loss: 0.6347\n",
      "Epoch 11, Accuracy 66.18%, Loss: 0.6981\n",
      "Epoch 11, Accuracy 66.42%, Loss: 0.7611\n",
      "Epoch 11, Accuracy 66.95%, Loss: 0.8223\n",
      "Epoch 11, Accuracy 66.91%, Loss: 0.8830\n",
      "Epoch 11, Accuracy 66.79%, Loss: 0.9463\n",
      "Epoch 12, Accuracy 66.57%, Loss: 0.0005\n",
      "Epoch 12, Accuracy 66.81%, Loss: 0.0615\n",
      "Epoch 12, Accuracy 66.47%, Loss: 0.1208\n",
      "Epoch 12, Accuracy 67.70%, Loss: 0.1797\n",
      "Epoch 12, Accuracy 67.74%, Loss: 0.2423\n",
      "Epoch 12, Accuracy 67.30%, Loss: 0.2998\n",
      "Epoch 12, Accuracy 65.95%, Loss: 0.3568\n",
      "Epoch 12, Accuracy 67.38%, Loss: 0.4147\n",
      "Epoch 12, Accuracy 66.84%, Loss: 0.4748\n",
      "Epoch 12, Accuracy 68.95%, Loss: 0.5335\n",
      "Epoch 12, Accuracy 68.36%, Loss: 0.5906\n",
      "Epoch 12, Accuracy 67.91%, Loss: 0.6480\n",
      "Epoch 12, Accuracy 66.82%, Loss: 0.7087\n",
      "Epoch 12, Accuracy 68.65%, Loss: 0.7680\n",
      "Epoch 12, Accuracy 69.17%, Loss: 0.8277\n",
      "Epoch 12, Accuracy 69.59%, Loss: 0.8861\n",
      "Epoch 13, Accuracy 69.70%, Loss: 0.0005\n",
      "Epoch 13, Accuracy 68.77%, Loss: 0.0549\n",
      "Epoch 13, Accuracy 68.69%, Loss: 0.1116\n",
      "Epoch 13, Accuracy 68.59%, Loss: 0.1666\n",
      "Epoch 13, Accuracy 70.02%, Loss: 0.2219\n",
      "Epoch 13, Accuracy 70.12%, Loss: 0.2765\n",
      "Epoch 13, Accuracy 68.42%, Loss: 0.3318\n",
      "Epoch 13, Accuracy 70.03%, Loss: 0.3888\n",
      "Epoch 13, Accuracy 70.94%, Loss: 0.4442\n",
      "Epoch 13, Accuracy 70.29%, Loss: 0.4998\n",
      "Epoch 13, Accuracy 70.62%, Loss: 0.5553\n",
      "Epoch 13, Accuracy 71.02%, Loss: 0.6114\n",
      "Epoch 13, Accuracy 69.83%, Loss: 0.6676\n",
      "Epoch 13, Accuracy 70.37%, Loss: 0.7227\n",
      "Epoch 13, Accuracy 69.06%, Loss: 0.7780\n",
      "Epoch 13, Accuracy 71.67%, Loss: 0.8340\n",
      "Epoch 14, Accuracy 70.86%, Loss: 0.0004\n",
      "Epoch 14, Accuracy 70.55%, Loss: 0.0546\n",
      "Epoch 14, Accuracy 69.71%, Loss: 0.1071\n",
      "Epoch 14, Accuracy 70.73%, Loss: 0.1585\n",
      "Epoch 14, Accuracy 71.03%, Loss: 0.2096\n",
      "Epoch 14, Accuracy 71.44%, Loss: 0.2613\n",
      "Epoch 14, Accuracy 70.68%, Loss: 0.3144\n",
      "Epoch 14, Accuracy 70.66%, Loss: 0.3666\n",
      "Epoch 14, Accuracy 70.68%, Loss: 0.4190\n",
      "Epoch 14, Accuracy 72.52%, Loss: 0.4700\n",
      "Epoch 14, Accuracy 72.05%, Loss: 0.5221\n",
      "Epoch 14, Accuracy 71.50%, Loss: 0.5755\n",
      "Epoch 14, Accuracy 71.13%, Loss: 0.6279\n",
      "Epoch 14, Accuracy 72.37%, Loss: 0.6808\n",
      "Epoch 14, Accuracy 71.74%, Loss: 0.7325\n",
      "Epoch 14, Accuracy 71.70%, Loss: 0.7832\n",
      "Epoch 15, Accuracy 71.57%, Loss: 0.0008\n",
      "Epoch 15, Accuracy 72.73%, Loss: 0.0504\n",
      "Epoch 15, Accuracy 71.83%, Loss: 0.1010\n",
      "Epoch 15, Accuracy 72.86%, Loss: 0.1485\n",
      "Epoch 15, Accuracy 73.08%, Loss: 0.1967\n",
      "Epoch 15, Accuracy 73.10%, Loss: 0.2479\n",
      "Epoch 15, Accuracy 72.49%, Loss: 0.2962\n",
      "Epoch 15, Accuracy 72.15%, Loss: 0.3440\n",
      "Epoch 15, Accuracy 71.84%, Loss: 0.3924\n",
      "Epoch 15, Accuracy 72.45%, Loss: 0.4424\n",
      "Epoch 15, Accuracy 73.71%, Loss: 0.4918\n",
      "Epoch 15, Accuracy 72.90%, Loss: 0.5393\n",
      "Epoch 15, Accuracy 72.88%, Loss: 0.5890\n",
      "Epoch 15, Accuracy 73.58%, Loss: 0.6366\n",
      "Epoch 15, Accuracy 73.05%, Loss: 0.6856\n",
      "Epoch 15, Accuracy 71.04%, Loss: 0.7358\n",
      "Epoch 16, Accuracy 73.95%, Loss: 0.0006\n",
      "Epoch 16, Accuracy 74.17%, Loss: 0.0463\n",
      "Epoch 16, Accuracy 73.74%, Loss: 0.0936\n",
      "Epoch 16, Accuracy 73.84%, Loss: 0.1400\n",
      "Epoch 16, Accuracy 73.64%, Loss: 0.1861\n",
      "Epoch 16, Accuracy 73.27%, Loss: 0.2333\n",
      "Epoch 16, Accuracy 72.89%, Loss: 0.2791\n",
      "Epoch 16, Accuracy 72.40%, Loss: 0.3251\n",
      "Epoch 16, Accuracy 72.03%, Loss: 0.3740\n",
      "Epoch 16, Accuracy 72.78%, Loss: 0.4201\n",
      "Epoch 16, Accuracy 74.04%, Loss: 0.4689\n",
      "Epoch 16, Accuracy 74.31%, Loss: 0.5146\n",
      "Epoch 16, Accuracy 74.52%, Loss: 0.5598\n",
      "Epoch 16, Accuracy 74.83%, Loss: 0.6053\n",
      "Epoch 16, Accuracy 73.83%, Loss: 0.6505\n",
      "Epoch 16, Accuracy 74.59%, Loss: 0.6958\n",
      "Epoch 17, Accuracy 74.95%, Loss: 0.0003\n",
      "Epoch 17, Accuracy 73.57%, Loss: 0.0422\n",
      "Epoch 17, Accuracy 74.48%, Loss: 0.0866\n",
      "Epoch 17, Accuracy 74.40%, Loss: 0.1313\n",
      "Epoch 17, Accuracy 73.80%, Loss: 0.1761\n",
      "Epoch 17, Accuracy 75.30%, Loss: 0.2184\n",
      "Accuracy reached 75%, saving model and stopping training.\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "model = AlexNet_CIFAR10().to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # 交叉熵损失\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01)  # Adam 优化器\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Adam 优化器\n",
    "\n",
    "accuracy_threshold = 75\n",
    "# 训练模型\n",
    "num_epochs = 20\n",
    "\n",
    "stop_training = False\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for iter, data in enumerate(trainloader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "        if iter % 100 == 0:\n",
    "            accuracy = accuracy_cal(model) \n",
    "            model.train()\n",
    "            print(f\"Epoch {epoch+1}, Accuracy {accuracy:.2f}%, Loss: {running_loss / len(trainloader):.4f}\")\n",
    "            if accuracy >= accuracy_threshold:\n",
    "                stop_training = True\n",
    "                print(f\"Accuracy reached {accuracy_threshold}%, saving model and stopping training.\")\n",
    "                torch.save(model.state_dict(), PRE_TRAINED)  # 保存模型\n",
    "                break\n",
    "    if stop_training:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, images, labels):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # print(\"LoRA+LC Training Loss (Decomposed): {}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECOMPOSED_LAYERS = [\"classifier.1.weight\", \"classifier.4.weight\"]\n",
    "RANK = -1\n",
    "SCALING = -1\n",
    "\n",
    "DLORA_LC_LOC = \"./my_test/\" + TASK_NAME + \"/dlora-lc\"\n",
    "if not os.path.exists(DLORA_LC_LOC):\n",
    "    os.makedirs(DLORA_LC_LOC)\n",
    "\n",
    "LC_LOC = \"./my_test/\" + TASK_NAME + \"/lc\"\n",
    "if not os.path.exists(LC_LOC):\n",
    "    os.makedirs(LC_LOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SunJingYi\\AppData\\Local\\Temp\\ipykernel_37588\\4240735574.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  baseline_model.load_state_dict(torch.load(PRE_TRAINED))\n",
      "C:\\Users\\SunJingYi\\AppData\\Local\\Temp\\ipykernel_37588\\4240735574.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lc_checkpoint_model.load_state_dict(torch.load(PRE_TRAINED))\n",
      "C:\\Users\\SunJingYi\\AppData\\Local\\Temp\\ipykernel_37588\\4240735574.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  load_sd_decomp(torch.load(PRE_TRAINED), delta_lora_model, DECOMPOSED_LAYERS)\n",
      "C:\\Users\\SunJingYi\\AppData\\Local\\Temp\\ipykernel_37588\\4240735574.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  load_sd_decomp(torch.load(PRE_TRAINED), dlora_lc_model, DECOMPOSED_LAYERS)\n",
      "C:\\Users\\SunJingYi\\AppData\\Local\\Temp\\ipykernel_37588\\4240735574.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  last_dlora_lc_baseline_checkpoint.load_state_dict(torch.load(PRE_TRAINED))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full accuracy: 75.29, LC accuracy: 75.29, Decomposed-Full accuracy: 75.3, Decomposed-Restored accuracy: 75.3\n",
      "Full accuracy: 75.3, LC accuracy: 75.29, Decomposed-Full accuracy: 75.3, Decomposed-Restored accuracy: 75.3\n",
      "Full accuracy: 75.29, LC accuracy: 75.29, Decomposed-Full accuracy: 75.29, Decomposed-Restored accuracy: 75.29\n",
      "Full accuracy: 75.33, LC accuracy: 75.32, Decomposed-Full accuracy: 75.29, Decomposed-Restored accuracy: 75.29\n",
      "Full accuracy: 75.36, LC accuracy: 75.36, Decomposed-Full accuracy: 75.29, Decomposed-Restored accuracy: 75.29\n",
      "Full accuracy: 75.35, LC accuracy: 75.35, Decomposed-Full accuracy: 75.29, Decomposed-Restored accuracy: 75.29\n",
      "Full accuracy: 75.34, LC accuracy: 75.34, Decomposed-Full accuracy: 75.29, Decomposed-Restored accuracy: 75.29\n",
      "Full accuracy: 75.35, LC accuracy: 75.35, Decomposed-Full accuracy: 75.29, Decomposed-Restored accuracy: 75.29\n",
      "Full accuracy: 75.36, LC accuracy: 75.35, Decomposed-Full accuracy: 75.29, Decomposed-Restored accuracy: 75.29\n",
      "Full accuracy: 75.36, LC accuracy: 75.36, Decomposed-Full accuracy: 75.29, Decomposed-Restored accuracy: 75.29\n",
      "Full accuracy: 75.35, LC accuracy: 75.35, Decomposed-Full accuracy: 75.29, Decomposed-Restored accuracy: 75.29\n",
      "Full accuracy: 75.37, LC accuracy: 75.37, Decomposed-Full accuracy: 75.28, Decomposed-Restored accuracy: 75.28\n",
      "Full accuracy: 75.37, LC accuracy: 75.37, Decomposed-Full accuracy: 75.29, Decomposed-Restored accuracy: 75.29\n",
      "Full accuracy: 75.38, LC accuracy: 75.38, Decomposed-Full accuracy: 75.29, Decomposed-Restored accuracy: 75.29\n",
      "Full accuracy: 75.39, LC accuracy: 75.39, Decomposed-Full accuracy: 75.29, Decomposed-Restored accuracy: 75.29\n",
      "Full accuracy: 75.42, LC accuracy: 75.42, Decomposed-Full accuracy: 75.29, Decomposed-Restored accuracy: 75.29\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 146\u001b[0m\n\u001b[0;32m    143\u001b[0m old_lc_delta, old_lc_bias \u001b[38;5;241m=\u001b[39m olc\u001b[38;5;241m.\u001b[39mgenerate_delta(prev_state, cstate, DECOMPOSED_LAYERS)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# print(\"Compressing delta for old_lc\")\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# compressed_delta = olc.compress_delta(old_lc_delta, num_bits = 3)\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m olc_compressed_delta, update_prev \u001b[38;5;241m=\u001b[39m \u001b[43molc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mold_lc_delta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m olc\u001b[38;5;241m.\u001b[39msave_checkpoint(LC_LOC \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/set_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(current_set_old_lc), olc_compressed_delta, \n\u001b[0;32m    148\u001b[0m                     old_lc_bias, current_iter_old_lc)\n\u001b[0;32m    149\u001b[0m prev_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39madd(prev_state, update_prev)\n",
      "File \u001b[1;32mc:\\learn\\检查点压缩\\pfe_lc_lora new\\old_lc\\main.py:744\u001b[0m, in \u001b[0;36mcompress_data\u001b[1;34m(δt, num_bits, threshhold)\u001b[0m\n\u001b[0;32m    742\u001b[0m groups \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m value, exp, sign \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(δt, δt_exp, δt_sign):\n\u001b[1;32m--> 744\u001b[0m     groups[(exp, sign)]\u001b[38;5;241m.\u001b[39mappend(value)\n\u001b[0;32m    746\u001b[0m \u001b[38;5;66;03m# Calculate averages\u001b[39;00m\n\u001b[0;32m    747\u001b[0m bucket_list \u001b[38;5;241m=\u001b[39m [(np\u001b[38;5;241m.\u001b[39mmean(values), np\u001b[38;5;241m.\u001b[39marray(indices)) \u001b[38;5;28;01mfor\u001b[39;00m (indices, values) \u001b[38;5;129;01min\u001b[39;00m groups\u001b[38;5;241m.\u001b[39mitems()]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "num_epochs = 20\n",
    "\n",
    "full_accuracy = []\n",
    "decomposed_full_accuracy = []\n",
    "restored_accuracy = []\n",
    "lc_accuracy = []\n",
    "\n",
    "# 不使用lora\n",
    "\n",
    "baseline_model = AlexNet_CIFAR10().to(device)\n",
    "lc_checkpoint_model = AlexNet_CIFAR10().to(device)\n",
    "\n",
    "baseline_model.load_state_dict(torch.load(PRE_TRAINED))\n",
    "lc_checkpoint_model.load_state_dict(torch.load(PRE_TRAINED))\n",
    "\n",
    "# 使用lora\n",
    "\n",
    "w, b = getBase(baseline_model)\n",
    "delta_lora_model = AlexNet_CIFAR10LowRank(w, b, rank = RANK).to(device)\n",
    "dlora_lc_model = AlexNet_CIFAR10LowRank(w, b, rank = RANK).to(device)\n",
    "\n",
    "load_sd_decomp(torch.load(PRE_TRAINED), delta_lora_model, DECOMPOSED_LAYERS)\n",
    "load_sd_decomp(torch.load(PRE_TRAINED), dlora_lc_model, DECOMPOSED_LAYERS)\n",
    "\n",
    "# 对应的优化器\n",
    "learning_rate = 0.01\n",
    "baseline_optimizer = torch.optim.SGD(baseline_model.parameters(), lr = learning_rate)\n",
    "lc_checkpoint_optimizer = torch.optim.SGD(lc_checkpoint_model.parameters(), lr = learning_rate)\n",
    "delta_lora_optimizer = torch.optim.SGD(delta_lora_model.parameters(), lr = learning_rate)\n",
    "dlora_lc_optimizer = torch.optim.SGD(dlora_lc_model.parameters(), lr = learning_rate)\n",
    "\n",
    "# delta-lc压缩，创建第一个压缩点\n",
    "current_set = 0\n",
    "current_iter = 0\n",
    "set_path = \"/set_{}\".format(current_set)\n",
    "if not os.path.exists(DLORA_LC_LOC + set_path):\n",
    "    os.makedirs(DLORA_LC_LOC + set_path)\n",
    "dlora_lc_model = dlora_lc_model.to('cpu')\n",
    "dlora_lc_weights, dlora_lc_decomp_weights = lc.extract_weights(dlora_lc_model, DLORA_LC_LOC + \"/set_{}\".format(current_set), DECOMPOSED_LAYERS)\n",
    "dlora_lc_model = dlora_lc_model.to(device)\n",
    "# 上一个基线检查点，用于模拟恢复\n",
    "last_dlora_lc_baseline_checkpoint = AlexNet_CIFAR10()\n",
    "last_dlora_lc_baseline_checkpoint.load_state_dict(torch.load(PRE_TRAINED))\n",
    "\n",
    "\n",
    "# lc 压缩\n",
    "current_iter_old_lc = 0\n",
    "current_set_old_lc = 0\n",
    "\n",
    "lc_checkpoint_model = lc_checkpoint_model.to('cpu')\n",
    "cstate = lc_checkpoint_model.state_dict()\n",
    "set_path = \"/set_{}\".format(current_set_old_lc)\n",
    "if not os.path.exists(LC_LOC + set_path):\n",
    "    os.makedirs(LC_LOC + set_path)\n",
    "prev_state = olc.extract_weights(cstate, LC_LOC + set_path, DECOMPOSED_LAYERS)\n",
    "lc_checkpoint_model = lc_checkpoint_model.to(device)\n",
    "\n",
    "# 训练\n",
    "for epoch in range(num_epochs):\n",
    "    for iter, data in enumerate(trainloader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "        # baseline训练\n",
    "        train_model(baseline_model, baseline_optimizer, images, labels)\n",
    "\n",
    "        # lc-checkpoint训练\n",
    "        train_model(lc_checkpoint_model, lc_checkpoint_optimizer, images, labels)\n",
    "\n",
    "        # delta-lora训练\n",
    "        # train_model(delta_lora_model, delta_lora_optimizer, images, labels)\n",
    "\n",
    "        # delta-lc训练\n",
    "        train_model(dlora_lc_model, dlora_lc_optimizer, images, labels)\n",
    "    \n",
    "        ########################################\n",
    "        # dlora-lc部分\n",
    "        ########################################\n",
    "        # 每10个iteration保存新的基线检查点\n",
    "        if iter == 0 and epoch == 0:\n",
    "            pass\n",
    "        elif iter % 10 == 0:\n",
    "            # 模拟恢复：\n",
    "            # 1.读取最近的基线检查点，这里持久保存最近的基线检查点，因此可以减少一个读取过程\n",
    "            # 2.基线检查点加一堆delta lora来恢复到最新的完整检查点\n",
    "            last_dlora_lc_baseline_checkpoint = lazy_restore(dlora_lc_weights, dlora_lc_decomp_weights, bias, AlexNet_CIFAR10(), \n",
    "                                                    last_dlora_lc_baseline_checkpoint.state_dict(), DECOMPOSED_LAYERS, rank = RANK, scaling = SCALING)\n",
    "            \n",
    "            current_set += 1\n",
    "            current_iter = 0\n",
    "\n",
    "            # 3.保存最新的检查点\n",
    "            set_path = \"/set_{}\".format(current_set)\n",
    "            if not os.path.exists(DLORA_LC_LOC + set_path):\n",
    "                os.makedirs(DLORA_LC_LOC + set_path)\n",
    "            \n",
    "            # Rebuilding LoRA layers => reset model!\n",
    "            w, b = getBase(last_dlora_lc_baseline_checkpoint)\n",
    "            dlora_lc_model = AlexNet_CIFAR10LowRank(w, b, rank = RANK)\n",
    "            dlora_lc_optimizer = torch.optim.SGD(dlora_lc_model.parameters(), lr = learning_rate)\n",
    "            load_sd_decomp(last_dlora_lc_baseline_checkpoint.state_dict(), dlora_lc_model, DECOMPOSED_LAYERS)\n",
    "            \n",
    "            dlora_lc_model = dlora_lc_model.to('cpu')\n",
    "            dlora_lc_weights, dlora_lc_decomp_weights = lc.extract_weights(dlora_lc_model, DLORA_LC_LOC + \n",
    "                                                    \"/set_{}\".format(current_set), DECOMPOSED_LAYERS)\n",
    "            dlora_lc_model = dlora_lc_model.to(device)\n",
    "        else:\n",
    "            # delta lora\n",
    "            dlora_lc_model = dlora_lc_model.to('cpu')\n",
    "            delta, decomp_delta, bias = lc.generate_delta(dlora_lc_weights, dlora_lc_decomp_weights, dlora_lc_model.state_dict(), DECOMPOSED_LAYERS)\n",
    "            dlora_lc_model = dlora_lc_model.to(device)\n",
    "            # lc checkpoint compression\n",
    "            compressed_delta, full_delta, compressed_dcomp_delta, full_dcomp_delta  = lc.compress_delta(delta, decomp_delta)\n",
    "            # save\n",
    "            lc.save_checkpoint(compressed_delta, compressed_dcomp_delta, bias, current_iter, DLORA_LC_LOC + \"/set_{}\".format(current_set))\n",
    "            # update weights\n",
    "            dlora_lc_weights = np.add(dlora_lc_weights, full_delta) # Replace base with latest for delta to accumulate.\n",
    "            dlora_lc_decomp_weights = np.add(dlora_lc_decomp_weights, full_dcomp_delta)\n",
    "\n",
    "            current_iter += 1\n",
    "\n",
    "        ########################################\n",
    "        # lc部分\n",
    "        ########################################\n",
    "        if iter == 0 and epoch == 0:\n",
    "            pass\n",
    "        else:\n",
    "            if iter % 10 == 0:\n",
    "                lc_checkpoint_model = lc_checkpoint_model.to('cpu')\n",
    "                cstate = lc_checkpoint_model.state_dict()\n",
    "                current_set_old_lc += 1\n",
    "                current_iter_old_lc = 0\n",
    "                set_path = \"/set_{}\".format(current_set_old_lc)\n",
    "                if not os.path.exists(LC_LOC + set_path):\n",
    "                    os.makedirs(LC_LOC + set_path)\n",
    "                # torch.save(cstate, SAVE_LOC_OLC + set_path + \"/initial_model.pt\")\n",
    "                prev_state = olc.extract_weights(cstate, LC_LOC + set_path, DECOMPOSED_LAYERS)\n",
    "                lc_checkpoint_model = lc_checkpoint_model.to(device)\n",
    "            else:\n",
    "                lc_checkpoint_model = lc_checkpoint_model.to('cpu')\n",
    "                cstate = lc_checkpoint_model.state_dict()\n",
    "                old_lc_delta, old_lc_bias = olc.generate_delta(prev_state, cstate, DECOMPOSED_LAYERS)\n",
    "                # print(\"Compressing delta for old_lc\")\n",
    "                # compressed_delta = olc.compress_delta(old_lc_delta, num_bits = 3)\n",
    "                olc_compressed_delta, update_prev = olc.compress_data(old_lc_delta, num_bits = 3)\n",
    "                olc.save_checkpoint(LC_LOC + \"/set_{}\".format(current_set_old_lc), olc_compressed_delta, \n",
    "                                    old_lc_bias, current_iter_old_lc)\n",
    "                prev_state = np.add(prev_state, update_prev)\n",
    "                current_iter_old_lc += 1\n",
    "                lc_checkpoint_model = lc_checkpoint_model.to(device)\n",
    "\n",
    "        if iter % 100 == 0 and iter != 0:\n",
    "            full_accuracy.append(accuracy_cal(baseline_model))\n",
    "            decomposed_full_accuracy.append(accuracy_cal(dlora_lc_model))\n",
    "            restored_model = lazy_restore(dlora_lc_weights, dlora_lc_decomp_weights, bias, AlexNet_CIFAR10(), \n",
    "                                          last_dlora_lc_baseline_checkpoint.state_dict(), DECOMPOSED_LAYERS, \n",
    "                                          rank = RANK, scaling = SCALING)\n",
    "            \n",
    "            restored_model = restored_model.to(device)\n",
    "            restored_accuracy.append(accuracy_cal(restored_model))\n",
    "            restored_model = restored_model.to('cpu')\n",
    "            restored_lc_model = AlexNet_CIFAR10()\n",
    "            restored_lc_model.load_state_dict(olc.restore_state_dict(prev_state, old_lc_bias, \n",
    "                                                                  restored_model.state_dict(), DECOMPOSED_LAYERS))\n",
    "            restored_lc_model = restored_lc_model.to(device)\n",
    "            lc_accuracy.append(accuracy_cal(restored_lc_model))\n",
    "            restored_lc_model = restored_lc_model.to('cpu')\n",
    "            print(\"Full accuracy: {}, LC accuracy: {}, Decomposed-Full accuracy: {}, Decomposed-Restored accuracy: {}\".format(\n",
    "                full_accuracy[-1], lc_accuracy[-1], decomposed_full_accuracy[-1], restored_accuracy[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize = (30, 5))\n",
    "plt.title(\"AlexNet, Accuracy\")\n",
    "plt.plot(full_accuracy, label = \"Default AlexNet\")\n",
    "plt.plot(lc_accuracy, label = \"LC AlexNet\")\n",
    "plt.plot(decomposed_full_accuracy, label = \"dLoRA AlexNet\")\n",
    "plt.plot(restored_accuracy, label = \"dLoRA + LC AlexNet\")\n",
    "plt.xticks([x for x in range(0, 120) if x % 6 == 0], [x for x in range(0, 20)])\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig(\"./my_test/\" + TASK_NAME + \"/AlexNet_accuracy.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()  # 关闭图像，释放资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rangex = [x for x in range(0, 120) if x % 6 == 0]\n",
    "rangey = [x for x in range(0, 20)]\n",
    "plt.figure(figsize = (40, 10))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.set_title(\"AlexNet Absolute Accuracy Loss (Default AlexNet vs LC + dLoRA AlexNet / LC AlexNet)\")\n",
    "plt.plot(np.abs(np.subtract(np.array(full_accuracy), \n",
    "                     np.array(restored_accuracy))), label = \"LC + dLoRA AlexNet\")\n",
    "plt.plot(np.abs(np.subtract(np.array(full_accuracy), \n",
    "                     np.array(lc_accuracy))), label = \"LC AlexNet\")\n",
    "plt.legend()\n",
    "plt.xticks(rangex, rangey)\n",
    "plt.ylabel(\"Absolute Accuracy Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.axhline(y = 0.05, color = 'r')\n",
    "plt.ylim(0, 0.5)\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.set_title(\"AlexNet Absolute Restoration Accuracy Loss (LC + dLoRA AlexNet & LC AlexNet)\")\n",
    "plt.plot(np.abs(np.subtract(np.array(restored_accuracy), \n",
    "                     np.array(decomposed_full_accuracy))), label = \"LC + dLoRA AlexNet\")\n",
    "plt.plot(np.abs(np.subtract(np.array(full_accuracy), \n",
    "                     np.array(lc_accuracy))), label = \"LC AlexNet\")\n",
    "plt.legend()\n",
    "plt.ylim(0, 0.5)\n",
    "plt.axhline(y = 0.05, color = 'r')\n",
    "plt.xticks(rangex, rangey)\n",
    "plt.ylabel(\"Absolute Accuracy Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig(\"./my_test/\" + TASK_NAME + \"/AlexNet_loss.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()  # 关闭图像，释放资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getsize(sl):\n",
    "    dir = [x for x in os.listdir(sl)]\n",
    "    csize, usize = 0, 0\n",
    "    for set in dir:\n",
    "        for f in os.listdir(sl + \"/\" + set):\n",
    "            fp = sl + \"/{}/{}\".format(set, f)\n",
    "            csize += os.path.getsize(fp)\n",
    "            usize += 250 * math.pow(2, 10) # torch checkpoint same size\n",
    "    return csize, usize,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC-Checkpoint + GZIP\n",
      "Compression Ratio: 3.9829999999999997%, Space Savings: -2410.8740000000003%\n",
      "LoRA + LC-Checkpoint + GZIP\n",
      "Compression Ratio: 160.799%, Space Savings: 37.811%\n"
     ]
    }
   ],
   "source": [
    "compressed_size, uncompressed_size = getsize(DLORA_LC_LOC)\n",
    "a, b = evaluate_compression(uncompressed_size, compressed_size)\n",
    "compressed_size, uncompressed_size = getsize(LC_LOC)\n",
    "a1, b1 = evaluate_compression(uncompressed_size, compressed_size)\n",
    "\n",
    "print(\"LC-Checkpoint + GZIP\")\n",
    "print(\"Compression Ratio: {}%, Space Savings: {}%\".format(a1, b1))\n",
    "print(\"LoRA + LC-Checkpoint + GZIP\")\n",
    "print(\"Compression Ratio: {}%, Space Savings: {}%\".format(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"full_acc\" : full_accuracy,\n",
    "    \"decomposed_restored_accuracy\" : restored_accuracy,\n",
    "    \"decomposed_full_accuracy\" : decomposed_full_accuracy,\n",
    "    \"lc_restored_accuracy\" : lc_accuracy\n",
    "}\n",
    "with open(\"./my_test/\" + TASK_NAME + \"/data.json\", 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
