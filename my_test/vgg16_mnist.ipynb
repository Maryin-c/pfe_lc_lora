{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_NAME = \"vgg16_mnist\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "from src.models.VGG16NoLite_LowRank import getBase, VGG16NoLite_LowRank, load_sd_decomp\n",
    "from src.models.VGG16NoLite import VGG16NoLite\n",
    "\n",
    "\n",
    "import src.main as lc\n",
    "from src.utils.utils import evaluate_accuracy, lazy_restore, evaluate_compression\n",
    "import old_lc.main as olc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import json\n",
    "\n",
    "# 加载 MNIST 数据集\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0.1307, 0.3081)])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 选择设备（GPU or CPU）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED = \"./\" + TASK_NAME + \"/pretrained_model.pth\"\n",
    "if not os.path.exists(\"./\" + TASK_NAME):\n",
    "    os.makedirs(\"./\" + TASK_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_cal(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "model = VGG16NoLite().to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # 交叉熵损失\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01)  # Adam 优化器\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Adam 优化器\n",
    "\n",
    "accuracy_threshold = 75\n",
    "# 训练模型\n",
    "num_epochs = 10\n",
    "\n",
    "stop_training = False\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for iter, data in enumerate(trainloader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "        if iter % 100 == 0:\n",
    "            accuracy = accuracy_cal(model) \n",
    "            model.train()\n",
    "            print(f\"Epoch {epoch+1}, Accuracy {accuracy:.2f}%, Loss: {running_loss / len(trainloader):.4f}\")\n",
    "            if accuracy >= accuracy_threshold:\n",
    "                stop_training = True\n",
    "                print(f\"Accuracy reached {accuracy_threshold}%, saving model and stopping training.\")\n",
    "                torch.save(model.state_dict(), PRE_TRAINED)  # 保存模型\n",
    "                break\n",
    "    if stop_training:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, images, labels):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # print(\"LoRA+LC Training Loss (Decomposed): {}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECOMPOSED_LAYERS = ['classifier.0.weight', 'classifier.4.weight', 'classifier.8.weight']\n",
    "RANK = -1\n",
    "SCALING = -1\n",
    "\n",
    "DLORA_LC_LOC = \"./\" + TASK_NAME + \"/dlora-lc\"\n",
    "if not os.path.exists(DLORA_LC_LOC):\n",
    "    os.makedirs(DLORA_LC_LOC)\n",
    "\n",
    "LC_LOC = \"./\" + TASK_NAME + \"./lc\"\n",
    "if not os.path.exists(LC_LOC):\n",
    "    os.makedirs(LC_LOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "num_epochs = 1\n",
    "\n",
    "full_accuracy = []\n",
    "decomposed_full_accuracy = []\n",
    "restored_accuracy = []\n",
    "lc_accuracy = []\n",
    "\n",
    "# 不使用lora\n",
    "\n",
    "baseline_model = VGG16NoLite().to(device)\n",
    "lc_checkpoint_model = VGG16NoLite().to(device)\n",
    "\n",
    "baseline_model.load_state_dict(torch.load(PRE_TRAINED))\n",
    "lc_checkpoint_model.load_state_dict(torch.load(PRE_TRAINED))\n",
    "\n",
    "# 使用lora\n",
    "\n",
    "w, b = getBase(baseline_model)\n",
    "delta_lora_model = VGG16NoLite_LowRank(w, b, rank = RANK).to(device)\n",
    "dlora_lc_model = VGG16NoLite_LowRank(w, b, rank = RANK).to(device)\n",
    "\n",
    "load_sd_decomp(torch.load(PRE_TRAINED), delta_lora_model, DECOMPOSED_LAYERS)\n",
    "load_sd_decomp(torch.load(PRE_TRAINED), dlora_lc_model, DECOMPOSED_LAYERS)\n",
    "\n",
    "# 对应的优化器\n",
    "learning_rate = 0.01\n",
    "baseline_optimizer = torch.optim.SGD(baseline_model.parameters(), lr = learning_rate)\n",
    "lc_checkpoint_optimizer = torch.optim.SGD(lc_checkpoint_model.parameters(), lr = learning_rate)\n",
    "delta_lora_optimizer = torch.optim.SGD(delta_lora_model.parameters(), lr = learning_rate)\n",
    "dlora_lc_optimizer = torch.optim.SGD(dlora_lc_model.parameters(), lr = learning_rate)\n",
    "\n",
    "# delta-lc压缩，创建第一个压缩点\n",
    "current_set = 0\n",
    "current_iter = 0\n",
    "set_path = \"/set_{}\".format(current_set)\n",
    "if not os.path.exists(DLORA_LC_LOC + set_path):\n",
    "    os.makedirs(DLORA_LC_LOC + set_path)\n",
    "dlora_lc_model = dlora_lc_model.to('cpu')\n",
    "dlora_lc_weights, dlora_lc_decomp_weights = lc.extract_weights(dlora_lc_model, DLORA_LC_LOC + \"/set_{}\".format(current_set), DECOMPOSED_LAYERS)\n",
    "dlora_lc_model = dlora_lc_model.to(device)\n",
    "# 上一个基线检查点，用于模拟恢复\n",
    "last_dlora_lc_baseline_checkpoint = VGG16NoLite()\n",
    "last_dlora_lc_baseline_checkpoint.load_state_dict(torch.load(PRE_TRAINED))\n",
    "\n",
    "\n",
    "# lc 压缩\n",
    "current_iter_old_lc = 0\n",
    "current_set_old_lc = 0\n",
    "\n",
    "lc_checkpoint_model = lc_checkpoint_model.to('cpu')\n",
    "cstate = lc_checkpoint_model.state_dict()\n",
    "set_path = \"/set_{}\".format(current_set_old_lc)\n",
    "if not os.path.exists(LC_LOC + set_path):\n",
    "    os.makedirs(LC_LOC + set_path)\n",
    "prev_state = olc.extract_weights(cstate, LC_LOC + set_path, DECOMPOSED_LAYERS)\n",
    "lc_checkpoint_model = lc_checkpoint_model.to(device)\n",
    "\n",
    "# 训练\n",
    "for epoch in range(num_epochs):\n",
    "    for iter, data in enumerate(trainloader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "        # baseline训练\n",
    "        train_model(baseline_model, baseline_optimizer, images, labels)\n",
    "\n",
    "        # lc-checkpoint训练\n",
    "        train_model(lc_checkpoint_model, lc_checkpoint_optimizer, images, labels)\n",
    "\n",
    "        # delta-lora训练\n",
    "        # train_model(delta_lora_model, delta_lora_optimizer, images, labels)\n",
    "\n",
    "        # delta-lc训练\n",
    "        train_model(dlora_lc_model, dlora_lc_optimizer, images, labels)\n",
    "    \n",
    "        ########################################\n",
    "        # dlora-lc部分\n",
    "        ########################################\n",
    "        # 每10个iteration保存新的基线检查点\n",
    "        if iter == 0 and epoch == 0:\n",
    "            pass\n",
    "        elif iter % 10 == 0:\n",
    "            # 模拟恢复：\n",
    "            # 1.读取最近的基线检查点，这里持久保存最近的基线检查点，因此可以减少一个读取过程\n",
    "            # 2.基线检查点加一堆delta lora来恢复到最新的完整检查点\n",
    "            last_dlora_lc_baseline_checkpoint = lazy_restore(dlora_lc_weights, dlora_lc_decomp_weights, bias, VGG16NoLite(), \n",
    "                                                    last_dlora_lc_baseline_checkpoint.state_dict(), DECOMPOSED_LAYERS, rank = RANK, scaling = SCALING)\n",
    "            \n",
    "            current_set += 1\n",
    "            current_iter = 0\n",
    "\n",
    "            # 3.保存最新的检查点\n",
    "            set_path = \"/set_{}\".format(current_set)\n",
    "            if not os.path.exists(DLORA_LC_LOC + set_path):\n",
    "                os.makedirs(DLORA_LC_LOC + set_path)\n",
    "            \n",
    "            # Rebuilding LoRA layers => reset model!\n",
    "            w, b = getBase(last_dlora_lc_baseline_checkpoint)\n",
    "            dlora_lc_model = VGG16NoLite_LowRank(w, b, rank = RANK)\n",
    "            dlora_lc_optimizer = torch.optim.SGD(dlora_lc_model.parameters(), lr = learning_rate)\n",
    "            load_sd_decomp(last_dlora_lc_baseline_checkpoint.state_dict(), dlora_lc_model, DECOMPOSED_LAYERS)\n",
    "            \n",
    "            dlora_lc_model = dlora_lc_model.to('cpu')\n",
    "            dlora_lc_weights, dlora_lc_decomp_weights = lc.extract_weights(dlora_lc_model, DLORA_LC_LOC + \n",
    "                                                    \"/set_{}\".format(current_set), DECOMPOSED_LAYERS)\n",
    "            dlora_lc_model = dlora_lc_model.to(device)\n",
    "        else:\n",
    "            # delta lora\n",
    "            dlora_lc_model = dlora_lc_model.to('cpu')\n",
    "            delta, decomp_delta, bias = lc.generate_delta(dlora_lc_weights, dlora_lc_decomp_weights, dlora_lc_model.state_dict(), DECOMPOSED_LAYERS)\n",
    "            dlora_lc_model = dlora_lc_model.to(device)\n",
    "            # lc checkpoint compression\n",
    "            compressed_delta, full_delta, compressed_dcomp_delta, full_dcomp_delta  = lc.compress_delta(delta, decomp_delta)\n",
    "            # save\n",
    "            lc.save_checkpoint(compressed_delta, compressed_dcomp_delta, bias, current_iter, DLORA_LC_LOC + \"/set_{}\".format(current_set))\n",
    "            # update weights\n",
    "            dlora_lc_weights = np.add(dlora_lc_weights, full_delta) # Replace base with latest for delta to accumulate.\n",
    "            dlora_lc_decomp_weights = np.add(dlora_lc_decomp_weights, full_dcomp_delta)\n",
    "\n",
    "            current_iter += 1\n",
    "\n",
    "        ########################################\n",
    "        # lc部分\n",
    "        ########################################\n",
    "        if iter == 0 and epoch == 0:\n",
    "            pass\n",
    "        else:\n",
    "            if iter % 10 == 0:\n",
    "                lc_checkpoint_model = lc_checkpoint_model.to('cpu')\n",
    "                cstate = lc_checkpoint_model.state_dict()\n",
    "                current_set_old_lc += 1\n",
    "                current_iter_old_lc = 0\n",
    "                set_path = \"/set_{}\".format(current_set_old_lc)\n",
    "                if not os.path.exists(LC_LOC + set_path):\n",
    "                    os.makedirs(LC_LOC + set_path)\n",
    "                # torch.save(cstate, SAVE_LOC_OLC + set_path + \"/initial_model.pt\")\n",
    "                prev_state = olc.extract_weights(cstate, LC_LOC + set_path, DECOMPOSED_LAYERS)\n",
    "                lc_checkpoint_model = lc_checkpoint_model.to(device)\n",
    "            else:\n",
    "                lc_checkpoint_model = lc_checkpoint_model.to('cpu')\n",
    "                cstate = lc_checkpoint_model.state_dict()\n",
    "                old_lc_delta, old_lc_bias = olc.generate_delta(prev_state, cstate, DECOMPOSED_LAYERS)\n",
    "                # print(\"Compressing delta for old_lc\")\n",
    "                # compressed_delta = olc.compress_delta(old_lc_delta, num_bits = 3)\n",
    "                olc_compressed_delta, update_prev = olc.compress_data(old_lc_delta, num_bits = 3)\n",
    "                olc.save_checkpoint(LC_LOC + \"/set_{}\".format(current_set_old_lc), olc_compressed_delta, \n",
    "                                    old_lc_bias, current_iter_old_lc)\n",
    "                prev_state = np.add(prev_state, update_prev)\n",
    "                current_iter_old_lc += 1\n",
    "                lc_checkpoint_model = lc_checkpoint_model.to(device)\n",
    "\n",
    "        if iter % 100 == 0 and iter != 0:\n",
    "            full_accuracy.append(accuracy_cal(baseline_model))\n",
    "            decomposed_full_accuracy.append(accuracy_cal(dlora_lc_model))\n",
    "            restored_model = lazy_restore(dlora_lc_weights, dlora_lc_decomp_weights, bias, VGG16NoLite(), \n",
    "                                          last_dlora_lc_baseline_checkpoint.state_dict(), DECOMPOSED_LAYERS, \n",
    "                                          rank = RANK, scaling = SCALING)\n",
    "            \n",
    "            restored_model = restored_model.to(device)\n",
    "            restored_accuracy.append(accuracy_cal(restored_model))\n",
    "            restored_model = restored_model.to('cpu')\n",
    "            restored_lc_model = VGG16NoLite()\n",
    "            restored_lc_model.load_state_dict(olc.restore_state_dict(prev_state, old_lc_bias, \n",
    "                                                                  restored_model.state_dict(), DECOMPOSED_LAYERS))\n",
    "            restored_lc_model = restored_lc_model.to(device)\n",
    "            lc_accuracy.append(accuracy_cal(restored_lc_model))\n",
    "            restored_lc_model = restored_lc_model.to('cpu')\n",
    "            print(\"Full accuracy: {}, LC accuracy: {}, Decomposed-Full accuracy: {}, Decomposed-Restored accuracy: {}\".format(\n",
    "                full_accuracy[-1], lc_accuracy[-1], decomposed_full_accuracy[-1], restored_accuracy[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize = (30, 5))\n",
    "plt.title(\"VGG-16 No Lite, Accuracy\")\n",
    "plt.plot(full_accuracy, label = \"Default VGG-16 No Lite\")\n",
    "plt.plot(lc_accuracy, label = \"LC VGG-16 No Lite\")\n",
    "plt.plot(decomposed_full_accuracy, label = \"dLoRA VGG-16 No Lite\")\n",
    "plt.plot(restored_accuracy, label = \"dLoRA + LC VGG-16 No Lite\")\n",
    "plt.xticks([x for x in range(0, 120) if x % 6 == 0], [x for x in range(0, 20)])\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig(\"./\" + TASK_NAME + \"/VGG_16_No_Lite_accuracy.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()  # 关闭图像，释放资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rangex = [x for x in range(0, 120) if x % 6 == 0]\n",
    "rangey = [x for x in range(0, 20)]\n",
    "plt.figure(figsize = (40, 10))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.set_title(\"VGG-16 No Lite Absolute Accuracy Loss (Default VGG-16 No Lite vs LC + dLoRA VGG-16 No Lite / LC VGG-16 No Lite)\")\n",
    "plt.plot(np.abs(np.subtract(np.array(full_accuracy), \n",
    "                     np.array(restored_accuracy))), label = \"LC + dLoRA VGG-16 No Lite\")\n",
    "plt.plot(np.abs(np.subtract(np.array(full_accuracy), \n",
    "                     np.array(lc_accuracy))), label = \"LC VGG-16 No Lite\")\n",
    "plt.legend()\n",
    "plt.xticks(rangex, rangey)\n",
    "plt.ylabel(\"Absolute Accuracy Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.axhline(y = 0.05, color = 'r')\n",
    "plt.ylim(0, 0.5)\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.set_title(\"VGG-16 No Lite Absolute Restoration Accuracy Loss (LC + dLoRA VGG-16 No Lite & LC VGG-16 No Lite)\")\n",
    "plt.plot(np.abs(np.subtract(np.array(restored_accuracy), \n",
    "                     np.array(decomposed_full_accuracy))), label = \"LC + dLoRA VGG-16 No Lite\")\n",
    "plt.plot(np.abs(np.subtract(np.array(full_accuracy), \n",
    "                     np.array(lc_accuracy))), label = \"LC VGG-16 No Lite\")\n",
    "plt.legend()\n",
    "plt.ylim(0, 0.5)\n",
    "plt.axhline(y = 0.05, color = 'r')\n",
    "plt.xticks(rangex, rangey)\n",
    "plt.ylabel(\"Absolute Accuracy Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig(\"./\" + TASK_NAME + \"/VGG_16_No_Lite_loss.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()  # 关闭图像，释放资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def getsize(sl):\n",
    "    dir = [x for x in os.listdir(sl)]\n",
    "    csize, usize = 0, 0\n",
    "    for set in dir:\n",
    "        for f in os.listdir(sl + \"/\" + set):\n",
    "            fp = sl + \"/{}/{}\".format(set, f)\n",
    "            csize += os.path.getsize(fp)\n",
    "            usize += 250 * math.pow(2, 10) # torch checkpoint same size\n",
    "    return csize, usize,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_size, uncompressed_size = getsize(DLORA_LC_LOC)\n",
    "a, b = evaluate_compression(uncompressed_size, compressed_size)\n",
    "compressed_size, uncompressed_size = getsize(LC_LOC)\n",
    "a1, b1 = evaluate_compression(uncompressed_size, compressed_size)\n",
    "\n",
    "print(\"LC-Checkpoint + GZIP\")\n",
    "print(\"Compression Ratio: {}%, Space Savings: {}%\".format(a1, b1))\n",
    "print(\"LoRA + LC-Checkpoint + GZIP\")\n",
    "print(\"Compression Ratio: {}%, Space Savings: {}%\".format(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = {\n",
    "    \"full_acc\" : full_accuracy,\n",
    "    \"decomposed_restored_accuracy\" : restored_accuracy,\n",
    "    \"decomposed_full_accuracy\" : decomposed_full_accuracy,\n",
    "    \"lc_restored_accuracy\" : lc_accuracy\n",
    "}\n",
    "with open(\"./\" + TASK_NAME + \"/data.json\", 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
